<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>xtas.tasks.single &mdash; xtas 3.3 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootswatch-3.1.0/yeti/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/xtas.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '3.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../../_static/bootstrap-3.1.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="xtas 3.3 documentation" href="../../../index.html" />
    <link rel="up" title="Module code" href="../../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../index.html">
          xtas</a>
        <span class="navbar-text navbar-version pull-left"><b>3.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            <li class="divider-vertical"></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../index.html">Documentation <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Setting up xtas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">xtas tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extending.html">Extending xtas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../changelog.html">Changelog/release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently anticipated questions</a></li>
</ul>
</ul>
</li>
              
            
            
              
                
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <h1>Source code for xtas.tasks.single</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;Single-document tasks.</span>

<span class="sd">These process one document per function call (in Python) or REST call (via</span>
<span class="sd">the web server, ``/run`` or ``/run_es``). Most single-document tasks take a</span>
<span class="sd">document as their first argument. In the Python interface this may either be</span>
<span class="sd">a string or the result from ``xtas.tasks.es.es_document``, a reference to a</span>
<span class="sd">document in an Elasticsearch store.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>

<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">six.moves.urllib.parse</span> <span class="kn">import</span> <span class="n">urlencode</span>
<span class="kn">from</span> <span class="nn">six.moves.urllib.request</span> <span class="kn">import</span> <span class="n">urlopen</span>

<span class="kn">from</span> <span class="nn">cytoolz</span> <span class="kn">import</span> <span class="n">identity</span><span class="p">,</span> <span class="n">pipe</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">spotlight</span>

<span class="kn">from</span> <span class="nn">.es</span> <span class="kn">import</span> <span class="n">fetch</span>
<span class="kn">from</span> <span class="nn">..core</span> <span class="kn">import</span> <span class="n">app</span>
<span class="kn">from</span> <span class="nn">.._utils</span> <span class="kn">import</span> <span class="n">nltk_download</span>


<span class="nd">@app.task</span>
<div class="viewcode-block" id="guess_language"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.guess_language">[docs]</a><span class="k">def</span> <span class="nf">guess_language</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&quot;best&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Guess the language of a document.</span>

<span class="sd">    This function applies a statistical method to determine the language of a</span>
<span class="sd">    document. Depending on the ``output`` argument, it may either return a</span>
<span class="sd">    single language code, or a ranking of languages that a document may be</span>
<span class="sd">    written in, sorted by probability.</span>

<span class="sd">    Uses the langid library.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    doc : document</span>

<span class="sd">    output : string</span>
<span class="sd">        Either &quot;best&quot; to get a pair (code, prob) giving the two-letter code</span>
<span class="sd">        of the most probable language and its probability, or &quot;rank&quot; for a</span>
<span class="sd">        list of such pairs for all languages in the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">langid</span> <span class="kn">import</span> <span class="n">classify</span><span class="p">,</span> <span class="n">rank</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">func</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;best&quot;</span><span class="p">:</span> <span class="n">classify</span><span class="p">,</span> <span class="s">&quot;rank&quot;</span><span class="p">:</span> <span class="n">rank</span><span class="p">}[</span><span class="n">output</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;invalid parameter value output=</span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>

</div>
<span class="nd">@app.task</span>
<span class="k">def</span> <span class="nf">heideltime</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s">&#39;english&#39;</span><span class="p">):</span>
    <span class="c"># TODO document me</span>
    <span class="kn">from</span> <span class="nn">._heideltime</span> <span class="kn">import</span> <span class="n">call_heideltime</span>

    <span class="c"># TODO parse the TIMEX XML format.</span>
    <span class="k">return</span> <span class="n">call_heideltime</span><span class="p">(</span><span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">),</span> <span class="n">language</span><span class="p">)</span>


<span class="nd">@app.task</span>
<div class="viewcode-block" id="morphy"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.morphy">[docs]</a><span class="k">def</span> <span class="nf">morphy</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Lemmatize tokens using morphy, WordNet&#39;s lemmatizer.</span>

<span class="sd">    Finds the morphological root of all words in ``doc``, which is assumed to</span>
<span class="sd">    be written in English.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lemmas : list</span>
<span class="sd">        List of lemmas.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    stem_snowball: simpler approach to lemmatization (stemming).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># XXX Results will be better if we do POS tagging first, but then we</span>
    <span class="c"># need to map Penn Treebank tags to WordNet tags.</span>
    <span class="n">nltk_download</span><span class="p">(</span><span class="s">&#39;wordnet&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">map</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">,</span>
               <span class="n">_tokenize_if_needed</span><span class="p">(</span><span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)))</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="movie_review_polarity"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.movie_review_polarity">[docs]</a><span class="k">def</span> <span class="nf">movie_review_polarity</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Movie review polarity classifier.</span>

<span class="sd">    Determines whether the film review ``doc`` is positive or negative. Might</span>
<span class="sd">    be applicable to other types of document as well, but uses a statistical</span>
<span class="sd">    model trained on a corpus of user reviews of movies, all in English.</span>

<span class="sd">    See ``sentiwords_tag`` for a more general, but less direct, way of</span>
<span class="sd">    determining the opinion expressed in a text.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    p : float</span>
<span class="sd">        The probability that the movie review ``doc`` is positive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._polarity</span> <span class="kn">import</span> <span class="n">classify</span>
    <span class="k">return</span> <span class="n">classify</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

</div>
<span class="k">def</span> <span class="nf">_tokenize_if_needed</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="nb">basestring</span><span class="p">)</span> <span class="k">else</span> <span class="n">s</span>


<span class="nd">@app.task</span>
<span class="k">def</span> <span class="nf">nlner_conll</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Baseline NER tagger for Dutch, based on the CoNLL&#39;02 dataset.</span>

<span class="sd">    See http://www.clips.uantwerpen.be/conll2002/ner/ for the dataset and</span>
<span class="sd">    its license.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    frog: NER tagger and dependency parser for Dutch.</span>

<span class="sd">    stanford_ner_tag: NER tagger for English.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._nl_conll_ner</span> <span class="kn">import</span> <span class="n">ner</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">_tokenize_if_needed</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ner</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>


<span class="nd">@app.task</span>
<div class="viewcode-block" id="stem_snowball"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.stem_snowball">[docs]</a><span class="k">def</span> <span class="nf">stem_snowball</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">language</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stem words in doc using the Snowball stemmer.</span>

<span class="sd">    Set the parameter ``lang`` to a language code such as &quot;de&quot;, &quot;en&quot;, &quot;nl&quot;, or</span>
<span class="sd">    the special string &quot;porter&quot; to get Porter&#39;s classic stemming algorithm for</span>
<span class="sd">    English.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    morphy: smarter approach to stemming (lemmatization), but only for English.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">Stemmer</span> <span class="kn">import</span> <span class="n">Stemmer</span>
    <span class="k">return</span> <span class="n">Stemmer</span><span class="p">(</span><span class="n">language</span><span class="p">)</span><span class="o">.</span><span class="n">stemWords</span><span class="p">(</span><span class="n">_tokenize_if_needed</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="stanford_ner_tag"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.stanford_ner_tag">[docs]</a><span class="k">def</span> <span class="nf">stanford_ner_tag</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&quot;tokens&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Named entity recognizer using Stanford NER.</span>

<span class="sd">    English-language name detection and classification.</span>

<span class="sd">    Currently only supports the model &#39;english.all.3class.distsim.crf.ser.gz&#39;.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    doc : document</span>
<span class="sd">        Either a single string or a handle on a document in the ES store.</span>
<span class="sd">        Tokenization and sentence splitting will be done by Stanford NER using</span>
<span class="sd">        its own rules.</span>

<span class="sd">    output : string, optional</span>
<span class="sd">        Output format. &quot;tokens&quot; gives a list of (token, nerclass) triples,</span>
<span class="sd">        similar to the IO format but without the &quot;I-&quot;. &quot;names&quot; returns a list</span>
<span class="sd">        of (name, class pairs); since Stanford NER does not distinguish between</span>
<span class="sd">        start and continuation of name spans, the reconstruction of full names</span>
<span class="sd">        is heuristic.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tagged : list of list of pair of string</span>
<span class="sd">        For each sentence, a list of (word, tag) pairs.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    nlner_conll: NER tagger for Dutch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._stanford_ner</span> <span class="kn">import</span> <span class="n">tag</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tag</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="pos_tag"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.pos_tag">[docs]</a><span class="k">def</span> <span class="nf">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s">&#39;nltk&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform part-of-speech (POS) tagging for English.</span>

<span class="sd">    Currently only does English using the default model in NLTK.</span>

<span class="sd">    Expects a list of tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">!=</span> <span class="s">&#39;nltk&#39;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;unknown POS tagger </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">nltk_download</span><span class="p">(</span><span class="s">&#39;maxent_treebank_pos_tagger&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="sentiwords_tag"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.sentiwords_tag">[docs]</a><span class="k">def</span> <span class="nf">sentiwords_tag</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&quot;bag&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tag doc with SentiWords polarity priors.</span>

<span class="sd">    Performs left-to-right, longest-match annotation of token spans with</span>
<span class="sd">    polarities from SentiWords.</span>

<span class="sd">    Uses no part-of-speech information; when a span has multiple possible</span>
<span class="sd">    taggings in SentiWords, the mean is returned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    doc : document or list of strings</span>

<span class="sd">    output : string, optional</span>
<span class="sd">        Output format. Either &quot;bag&quot; for a histogram (dict) of annotated token</span>
<span class="sd">        span frequencies, or &quot;tokens&quot; a mixed list of strings and (list of</span>
<span class="sd">        strings, polarity) pairs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._sentiwords</span> <span class="kn">import</span> <span class="n">tag</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">_tokenize_if_needed</span><span class="p">(</span><span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>

    <span class="n">tagged</span> <span class="o">=</span> <span class="n">tag</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&quot;bag&quot;</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">polarity</span> <span class="ow">in</span> <span class="n">tagged</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">polarity</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
                <span class="n">d</span><span class="p">[</span><span class="n">ngram</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">d</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">polarity</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">d</span>

    <span class="k">elif</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&quot;tokens&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">ngram</span> <span class="k">if</span> <span class="n">polarity</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">ngram</span><span class="p">,</span> <span class="n">polarity</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">polarity</span> <span class="ow">in</span> <span class="n">tagged</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;unknown output format </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">output</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="tokenize"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.tokenize">[docs]</a><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenize text.</span>

<span class="sd">    Uses the NLTK function word_tokenize.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">nltk_download</span><span class="p">(</span><span class="s">&#39;punkt&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="semanticize"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.semanticize">[docs]</a><span class="k">def</span> <span class="nf">semanticize</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s">&#39;en&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run text through the UvA semanticizer.</span>

<span class="sd">    Calls the UvA semanticizer webservice to perform entity linking and</span>
<span class="sd">    returns the names/links it has found.</span>

<span class="sd">    See http://semanticize.uva.nl/doc/ for details.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    M. Guerini, L. Gatti and M. Turchi (2013). &quot;Sentiment analysis: How to</span>
<span class="sd">    derive prior polarities from SentiWordNet&quot;. Proc. EMNLP, pp. 1259-1269.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">lang</span><span class="o">.</span><span class="n">isalpha</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;not a valid language: </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">lang</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">&#39;http://semanticize.uva.nl/api/</span><span class="si">%s</span><span class="s">?</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">lang</span><span class="p">,</span>
                                                   <span class="n">urlencode</span><span class="p">({</span><span class="s">&#39;text&#39;</span><span class="p">:</span> <span class="n">text</span><span class="p">}))</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())[</span><span class="s">&#39;links&#39;</span><span class="p">]</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="untokenize"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.untokenize">[docs]</a><span class="k">def</span> <span class="nf">untokenize</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Undo tokenization.</span>

<span class="sd">    Simply concatenates the given tokens with spaces in between. Useful after</span>
<span class="sd">    tokenization and filtering.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    doc : string</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="s">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="frog"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.frog">[docs]</a><span class="k">def</span> <span class="nf">frog</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&#39;raw&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around the Frog lemmatizer/POS tagger/NER/dependency parser.</span>

<span class="sd">    Expects Frog to be running in server mode, listening on</span>
<span class="sd">    ``localhost:${XTAS_FROG_PORT}`` or port 9987 if the environment variable</span>
<span class="sd">    ``XTAS_FROG_PORT`` is not set. It is *not* started for you.</span>

<span class="sd">    Currently, the module is only tested with all frog modules active except</span>
<span class="sd">    for the NER and parser.</span>

<span class="sd">    The following line starts Frog in the correct way:</span>

<span class="sd">    ``frog -S ${XTAS_FROG_PORT:-9887}``</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output : string</span>
<span class="sd">        If &#39;raw&#39;, returns the raw output lines from Frog itself.</span>
<span class="sd">        If &#39;tokens&#39;, returns dictionaries for the tokens.</span>
<span class="sd">        If &#39;saf&#39;, returns a SAF dictionary.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `Frog homepage &lt;http://ilk.uvt.nl/frog/&gt;`_</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    nlner_conll: simple NER tagger for Dutch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._frog</span> <span class="kn">import</span> <span class="n">call_frog</span><span class="p">,</span> <span class="n">parse_frog</span><span class="p">,</span> <span class="n">frog_to_saf</span>
    <span class="k">if</span> <span class="n">output</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;raw&#39;</span><span class="p">,</span> <span class="s">&#39;tokens&#39;</span><span class="p">,</span> <span class="s">&#39;saf&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Uknown output: {output}, &quot;</span>
                         <span class="s">&quot;please choose either raw, tokens, or saf&quot;</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="nb">locals</span><span class="p">()))</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">call_frog</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&#39;raw&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;tokens&#39;</span><span class="p">,</span> <span class="s">&#39;saf&#39;</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">parse_frog</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&#39;tokens&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">frog_to_saf</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="dbpedia_spotlight"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.dbpedia_spotlight">[docs]</a><span class="k">def</span> <span class="nf">dbpedia_spotlight</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s">&#39;en&#39;</span><span class="p">,</span> <span class="n">conf</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">supp</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">api_url</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run text through a DBpedia Spotlight instance.</span>

<span class="sd">    Calls the DBpedia Spotlight instance to perform entity linking and</span>
<span class="sd">    returns the names/links it has found.</span>

<span class="sd">    See http://spotlight.dbpedia.org/ for details.</span>
<span class="sd">    This task uses a Python client for DBp Spotlight:</span>
<span class="sd">    https://github.com/aolieman/pyspotlight</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">fetch</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="n">endpoints_by_language</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">&#39;en&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2222/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;de&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2226/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;nl&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2232/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;fr&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2225/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;it&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2230/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;ru&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2227/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;es&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2231/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;pt&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2228/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;hu&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2229/rest&quot;</span><span class="p">,</span>
        <span class="s">&#39;tr&#39;</span><span class="p">:</span> <span class="s">&quot;http://spotlight.sztaki.hu:2235/rest&quot;</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">lang</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">endpoints_by_language</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">api_url</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Not a valid language code: </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">lang</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">api_url</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">api_url</span> <span class="o">=</span> <span class="n">endpoints_by_language</span><span class="p">[</span><span class="n">lang</span><span class="p">]</span>

    <span class="n">api_url</span> <span class="o">+=</span> <span class="s">&quot;/candidates&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">spotlight_resp</span> <span class="o">=</span> <span class="n">spotlight</span><span class="o">.</span><span class="n">candidates</span><span class="p">(</span>
            <span class="n">api_url</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">conf</span><span class="p">,</span>
            <span class="n">support</span><span class="o">=</span><span class="n">supp</span><span class="p">,</span>
            <span class="n">spotter</span><span class="o">=</span><span class="s">&#39;Default&#39;</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="n">spotlight</span><span class="o">.</span><span class="n">SpotlightException</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">&#39;error&#39;</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">}</span>

    <span class="c"># Return a list of annotation dictionaries</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">annotation</span> <span class="ow">in</span> <span class="n">spotlight_resp</span><span class="p">:</span>
        <span class="c"># Ignore annotations without disambiguation candidates</span>
        <span class="k">if</span> <span class="s">u&#39;resource&#39;</span> <span class="ow">in</span> <span class="n">annotation</span><span class="p">:</span>
            <span class="c"># Always return a list of resources, also for single candidates</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">annotation</span><span class="p">[</span><span class="s">u&#39;resource&#39;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">annotation</span><span class="p">[</span><span class="s">u&#39;resource&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">annotation</span><span class="p">[</span><span class="s">u&#39;resource&#39;</span><span class="p">]]</span>
            <span class="n">annotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">annotation</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">annotations</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="alpino"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.alpino">[docs]</a><span class="k">def</span> <span class="nf">alpino</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&quot;raw&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around the Alpino (dependency) parser for Dutch.</span>

<span class="sd">    Expects an environment variable ALPINO_HOME to point at</span>
<span class="sd">    the Alpino installation dir.</span>

<span class="sd">    The script uses the &#39;dependencies&#39; end_hook to generate lemmata and</span>
<span class="sd">    the dependency structure.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output : string</span>
<span class="sd">        If &#39;raw&#39;, returns the raw output from Alpino itself.</span>
<span class="sd">        If &#39;saf&#39;, returns a SAF dictionary.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `Alpino homepage &lt;http://www.let.rug.nl/vannoord/alp/Alpino/&gt;`_.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._alpino</span> <span class="kn">import</span> <span class="n">tokenize</span><span class="p">,</span> <span class="n">parse_raw</span><span class="p">,</span> <span class="n">interpret_parse</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">transf</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;raw&quot;</span><span class="p">:</span> <span class="n">identity</span><span class="p">,</span> <span class="s">&quot;saf&quot;</span><span class="p">:</span> <span class="n">interpret_parse</span><span class="p">}[</span><span class="n">output</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Unknown output format </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipe</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">fetch</span><span class="p">,</span> <span class="n">tokenize</span><span class="p">,</span> <span class="n">parse_raw</span><span class="p">,</span> <span class="n">transf</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="corenlp"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.corenlp">[docs]</a><span class="k">def</span> <span class="nf">corenlp</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&#39;raw&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around the CoreNLP parser.</span>

<span class="sd">    Expects ``$CORENLP_HOME`` to point to the CoreNLP installation dir.</span>

<span class="sd">    Tested with `CoreNLP 2014-01-04</span>
<span class="sd">    &lt;http://nlp.stanford.edu/software/stanford-corenlp-full-2014-01-04.zip&gt;`_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output : string</span>
<span class="sd">        If &#39;raw&#39;, returns the raw output lines from CoreNLP.</span>
<span class="sd">        If &#39;saf&#39;, returns a SAF dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._corenlp</span> <span class="kn">import</span> <span class="n">parse</span><span class="p">,</span> <span class="n">stanford_to_saf</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">transf</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;raw&quot;</span><span class="p">:</span> <span class="n">identity</span><span class="p">,</span> <span class="s">&quot;saf&quot;</span><span class="p">:</span> <span class="n">stanford_to_saf</span><span class="p">}[</span><span class="n">output</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Unknown output format </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipe</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">fetch</span><span class="p">,</span> <span class="n">parse</span><span class="p">,</span> <span class="n">transf</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="corenlp_lemmatize"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.corenlp_lemmatize">[docs]</a><span class="k">def</span> <span class="nf">corenlp_lemmatize</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&#39;raw&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around the CoreNLP lemmatizer.</span>

<span class="sd">    Expects ``$CORENLP_HOME`` to point to the CoreNLP installation dir.</span>

<span class="sd">    Tested with `CoreNLP 2014-01-04</span>
<span class="sd">    &lt;http://nlp.stanford.edu/software/stanford-corenlp-full-2014-01-04.zip&gt;`_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output : string</span>
<span class="sd">        If &#39;raw&#39;, returns the raw output lines from CoreNLP.</span>
<span class="sd">        If &#39;saf&#39;, returns a SAF dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._corenlp</span> <span class="kn">import</span> <span class="n">parse</span><span class="p">,</span> <span class="n">stanford_to_saf</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">transf</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;raw&quot;</span><span class="p">:</span> <span class="n">identity</span><span class="p">,</span> <span class="s">&quot;saf&quot;</span><span class="p">:</span> <span class="n">stanford_to_saf</span><span class="p">}[</span><span class="n">output</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Unknown output format </span><span class="si">%r</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipe</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">fetch</span><span class="p">,</span> <span class="n">parse</span><span class="p">,</span> <span class="n">transf</span><span class="p">)</span>

</div>
<span class="nd">@app.task</span>
<div class="viewcode-block" id="semafor"><a class="viewcode-back" href="../../../api.html#xtas.tasks.single.semafor">[docs]</a><span class="k">def</span> <span class="nf">semafor</span><span class="p">(</span><span class="n">saf</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper around the Semafor semantic parser.</span>

<span class="sd">    Expects semafor running in server mode listening to</span>
<span class="sd">    ``${SEMAFOR_HOST}:${SEMAFOR_PORT}`` (defaults to localhost:9888).</span>
<span class="sd">    It also expects ``$CORENLP_HOME`` to point to the CoreNLP installation dir.</span>

<span class="sd">    Input is expected to be a &#39;SAF&#39; dictionary with trees and tokens.</span>
<span class="sd">    Output is a SAF dictionary with a frames attribute added.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    * `Semafor GitHub page &lt;https://github.com/sammthomson/semafor&gt;&#39;_.</span>
<span class="sd">    * `CoreNLP home page &lt;http://nlp.stanford.edu/software/corenlp.shtml&gt;&#39;_.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">._semafor</span> <span class="kn">import</span> <span class="n">add_frames</span>
    <span class="n">add_frames</span><span class="p">(</span><span class="n">saf</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">saf</span></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2013–2015 Netherlands eScience Center, University of Amsterdam.<br/>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>